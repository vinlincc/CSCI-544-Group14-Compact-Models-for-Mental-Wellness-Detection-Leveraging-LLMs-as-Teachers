{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a616c3c1",
   "metadata": {},
   "source": [
    "# Run Fine-tune CoT on OpenAI using our `oai` module\n",
    "\n",
    "This notebook contains code to (1) generate reasoning samples from teacher models (e.g., GPT-3 175B `text-davinci-002`), (2) fine-tune student models (e.g., GPT-3 0.3B `ada`) and (3) generate and evaluate samples from fine-tuned student models.\n",
    "\n",
    "- To run from scratch, first download and save original benchmark data (see README).\n",
    "- To use existing teacher-generated samples, first download and save original benchmark data and teacher completion data (see README). Then, replace the completion_key `zs_cot_test` with `zs_cot` in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a6ccc",
   "metadata": {},
   "source": [
    "### TODO: Set OpenAI Key\n",
    "\n",
    "Create an account on OpenAI and retrieve your API key. Experiments will incurs fees on your OpenAI account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2587ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa4cf8",
   "metadata": {},
   "source": [
    "### Imports and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a11f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.completion_dataset import CompletionMetadata, CompletionDataset\n",
    "from oai.inference import infer_completion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be7d870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#teacher_base_model = \"text-davinci-002\"  # GPT-3 (175B)\n",
    "teacher_base_model = \"gpt-3.5-turbo-instruct\"\n",
    "#base_model = \"ada\"                       # GPT-3 (0.3B)\n",
    "#base_model = \"babbage\"                   # GPT-3 (1.3B)\n",
    "base_model = \"curie\"                     # GPT-3 (6.7B)\n",
    "#dataset_key = \"multiwd\"\n",
    "dataset_key = \"lrf\"\n",
    "# dataset_key = \"multiwdsmall\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043037d",
   "metadata": {},
   "source": [
    "## Infer teacher completions using OpenAI (generate CompletionDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fa53308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, completion_key identifies the method used to generate completions\n",
    "# Note, prediction_template selects the prediction template from those pre-defined in\n",
    "#       `oai.data.format.Formatter`.\n",
    "completion_metadata = CompletionMetadata(base_model=teacher_base_model, completion_key=\"zs_cot\",\n",
    "                                         dataset_key=dataset_key, prediction_template=\"zs_cot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939cfcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.split import load_train_test_split \n",
    "train, test = load_train_test_split(dataset_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d1d824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 55184 samples from:\n",
      "/home/azureuser/reasoning-teacher/saved/completion_data/B_gpt-3.5-turbo-instruct__C_zs_cot/D_lrf.json\n",
      "All 3449 samples have been completed.\n"
     ]
    }
   ],
   "source": [
    "# Run Zero-shot-CoT step 1 (rationale generation)\n",
    "# Note, sample_indices=None means we want to infer on all samples\n",
    "completion_dataset = infer_completion_data(completion_metadata, zs_cot_step=1,\n",
    "                                           sample_indices=train, augs=1, temperature=0,\n",
    "                                           max_tokens=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "042067fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4900 samples from:\n",
      "/home/azureuser/reasoning-teacher/saved/completion_data/B_gpt-3.5-turbo-instruct__C_zs_cot/D_multiwd.json\n",
      "Inferring completions for 520 remaining samples (total=4900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring completions via OpenAI: 100%|██████████| 520/520 [00:32<00:00, 15.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run Zero-shot-CoT step 2 (answer)\n",
    "completion_dataset = infer_completion_data(completion_metadata, zs_cot_step=2,\n",
    "                                           sample_indices=train, augs=1, temperature=0,\n",
    "                                           max_tokens=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19e754",
   "metadata": {},
   "source": [
    "## Load CompletionDataset and evaluate test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995c950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.completion_dataset import CompletionIdentifier\n",
    "from data.split import load_train_test_split \n",
    "from evaluation.evaluator import Evaluator\n",
    "from evaluation.summary import summarize_evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cf87485",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_identifier = CompletionIdentifier(teacher_base_model, \"zs_cot\", dataset_key)\n",
    "completion_dataset = CompletionDataset.load(completion_identifier)\n",
    "# Note, completion_metadata can be used instead of completion_identifier such as below\n",
    "# completion_dataset = CompletionDataset.load(completion_metadata)\n",
    "train, test = load_train_test_split(dataset_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c80ce146",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator.for_completion_dataset(completion_dataset)\n",
    "evaluation = evaluator.evaluate_completion_dataset(completion_dataset, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36c1760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>completion_index</th>\n",
       "      <th>correct</th>\n",
       "      <th>contains_answer</th>\n",
       "      <th>correct_format</th>\n",
       "      <th>complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index  completion_index  correct  contains_answer  correct_format  \\\n",
       "0             0                 0     True             True           False   \n",
       "1             0                 1     True             True           False   \n",
       "2             0                 2     True             True           False   \n",
       "3             0                 3     True             True           False   \n",
       "4             0                 4     True             True           False   \n",
       "\n",
       "   complete  \n",
       "0      True  \n",
       "1      True  \n",
       "2      True  \n",
       "3      True  \n",
       "4      True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0d58e46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.565765306122449,\n",
       " 'contains_answer': 0.565765306122449,\n",
       " 'correct_format': 1.0,\n",
       " 'complete': 0.9997831632653061}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_evaluation(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24187a50",
   "metadata": {},
   "source": [
    "## Create fine-tune `File` and `Finetune` using training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd27aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oai.finetune import init_finetune, generate_finetune_data_from_completion_dataset\n",
    "from oai.utils.api_wrapper import fetch_model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4edefd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace \"zs_cot_test\" with \"zs_cot\" to use our teacher-generated completions (see README for how to download).\n",
    "completion_identifier = CompletionIdentifier(teacher_base_model, \"zs_cot\", dataset_key)\n",
    "completion_dataset = CompletionDataset.load(completion_identifier)\n",
    "train, test = load_train_test_split(dataset_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee88849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetune_key = \"zs_cot_{}\".format(dataset_key)\n",
    "#train_key = \"ft_cot\"\n",
    "#finetune_key = \"zs_cot_auto_j_rate_6_{}\".format(dataset_key)\n",
    "#finetune_key = \"zs_cot_auto_j_rate_5_{}\".format(dataset_key)\n",
    "#finetune_key = \"zs_cot_8_shots_{}\".format(dataset_key)\n",
    "#finetune_key = \"zs_cot_16_shots_{}\".format(dataset_key)\n",
    "finetune_key = \"zs_cot_baseline_{}\".format(dataset_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6c7289a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zs_cot_baseline_lrf'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, finetune_key is a unique identifier for the finetuning data and should contain the source dataset\n",
    "generate_finetune_data_from_completion_dataset(completion_dataset=completion_dataset,\n",
    "                                               prediction_template=\"ft_cot_token\",\n",
    "                                               finetune_key=finetune_key,\n",
    "                                               sample_indices=train,\n",
    "                                               only_correct=True,  # default\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c98c87e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"prompt\": \"All my life i've been going through shit (only 17 years old) and when things started to get better i crashed. I can't get myself to get out of bed no matter how much i try, my family understands but do still not approve since my grades dropped from all A's to E-C. It has been like this for 1-2 years now and none of my friends understands how It's like, I can't really blame them either since I don't like talking about it and i've always been taught to be a man and keep this stuff to myself. They just see a lazy fuck who is too irresponsible to go too school, same with my teachers. Idk if typing here is going to help at all but if anyone has some tips/advice on how to get motivated again i would be super happy. Does the post shows risk of thwarted belongingness? You only need to answer yes/no. ###\",\n",
      "    \"completion\": \" --> yes END\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Inspect finetune data\n",
    "import json\n",
    "from paths import get_finetune_data_path\n",
    "with open(get_finetune_data_path(\"openai\", finetune_key)) as f:\n",
    "    print(json.dumps(json.loads(f.readline()), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e45949f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_key = \"IRF_BASE\"\n",
    "#train_key = \"MultiWD_BASE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03bf8d56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: OpenAI File `zs_cot_baseline_lrf` already exists (likely already uploaded). Skipping.\n",
      "Created OpenAI finetune `B_curie__D_lrf__T_IRF_BASE`: `ft-FbA1zT4l8KlXckX5BFhMy9XF`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'B_curie__D_lrf__T_IRF_BASE'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, train_key identifies the method used to train the model, i.e., the method used to fine-tune the base model.\n",
    "init_finetune(finetune_key, base_model, dataset_key, train_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec628615",
   "metadata": {},
   "source": [
    "### Fetch fine-tuned `Model` id\n",
    "\n",
    "You need to keep calling this function to check if your `Finetune` is finished. Fine-tuning typically take about 5 minutes to 1 hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d83504c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching model ids from 8 finetunes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model_key                                                                       status              \n",
      "----------------------------------------------------------------------------------------------------\n",
      "B_curie__D_multiwd__T_multiwd                                                   failed              \n",
      "B_curie__D_lrf__T_ft_cot_baseline                                               failed              \n",
      "B_ada__D_lrf__T_ft_cot_baseline2                                                failed              \n",
      "B_curie__D_lrf__T_ft_cot_baseline2                                              failed              \n",
      "B_ada__D_lrf__T_ft_cot_baseline3                                                failed              \n",
      "B_ada__D_lrf__T_ft_cot_baseline4                                                failed              \n",
      "B_curie__D_lrf__T_IRF_16_Shots                                                  failed              \n",
      "B_curie__D_lrf__T_IRF_BASE                                                      succeeded           \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 1 of 8 model ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_model_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ef518",
   "metadata": {},
   "source": [
    "### Access OpenAI metadata\n",
    "\n",
    "We use metadata files to map our identifiers (keys) to the identifier (ids) used by OpenAI objects.\n",
    "These can be accessed manually, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "01d9f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oai.utils.metadata import get_file_id, get_finetune_id, get_model_id, get_model_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = \"ada\"\n",
    "#base_model = \"babbage\"\n",
    "base_model = \"curie\"\n",
    "dataset_key = \"lrf\"\n",
    "#dataset_key = \"multiwd\"\n",
    "#train_key = \"MultiWD\"\n",
    "#train_key = \"IRF\"\n",
    "#train_key = \"IRF_Auto_J_Rate_6\"\n",
    "#train_key = \"IRF_Auto_J_Rate_5\"\n",
    "#train_key = \"MultiWD_Auto_J_Rate_6\"\n",
    "#train_key = \"IRF_8_Shots\"\n",
    "#train_key = \"MultiWD_8_Shots\"\n",
    "#train_key = \"IRF_16_Shots\"\n",
    "#train_key = \"MultiWD_16_Shots\"\n",
    "#train_key = \"MultiWD_BASE\"\n",
    "train_key = \"IRF_BASE\"\n",
    "#finetune_key = \"zs_cot_{}\".format(dataset_key)\n",
    "#finetune_key = \"zs_cot_auto_j_rate_6_{}\".format(dataset_key)\n",
    "#finetune_key = \"zs_cot_auto_j_rate_5_{}\".format(dataset_key)\n",
    "#finetune_key = \"zs_cot_8_shots_{}\".format(dataset_key)\n",
    "#finetune_key = \"zs_cot_16_shots_{}\".format(dataset_key)\n",
    "finetune_key = \"zs_cot_baseline_{}\".format(dataset_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "48975b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that `base_model`, `dataset_key`, `train_key` are joined together to form a `model_key` which\n",
    "# identifies fine-tuned models. There is a one-to-one-to-one mapping between a model_key, Finetune object,\n",
    "# and Model object.\n",
    "\n",
    "model_key = get_model_key(base_model, dataset_key, train_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5e342b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B_curie__D_lrf__T_IRF_BASE'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1a46489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-3u1xRGpDm8I8udvVoUzoBqEd'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that our `finetune_key` identifies the fine-tuning \"data\", therefore is mapped to a File object\n",
    "# rather than a Finetune object.\n",
    "get_file_id(finetune_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "95162d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft-FbA1zT4l8KlXckX5BFhMy9XF'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_finetune_id(model_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "71570d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'curie:ft-personal-2023-11-22-09-14-39'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_id(model_key)  # fetched by `fetch_model_ids()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0460e",
   "metadata": {},
   "source": [
    "## Infer student completions\n",
    "\n",
    "We only infer test set samples for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "df8e3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, completion_key and train_key are both \"ft_cot_test\". Recall that completion_key refers to\n",
    "# the method used to generate completions by the student model, and train_key refers to the method\n",
    "# used to train the student model.\n",
    "completion_metadata = CompletionMetadata(base_model=base_model, completion_key=\"zs_cot_final\",\n",
    "                                         dataset_key=dataset_key, finetune_key=finetune_key,\n",
    "                                         prediction_template=\"ft_cot_token\",\n",
    "                                         train_key=train_key, epoch=None)\n",
    "train, test = load_train_test_split(dataset_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aa1a4a0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new CompletionDataset at:\n",
      "/home/azureuser/reasoning-teacher/saved/completion_data/B_curie__C_zs_cot_final/D_lrf__T_IRF_BASE.json\n",
      "Inferring completions for 1479 remaining samples (total=1479)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring completions via OpenAI:   0%|          | 0/1479 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring completions via OpenAI: 100%|██████████| 1479/1479 [00:27<00:00, 53.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Note, `infer_completion_data` will find our new student model (that we fetched above) by using\n",
    "#       `base_model`, `dataset_key`, and `train_key` which is specified in `completion_metadata`.\n",
    "completion_dataset = infer_completion_data(completion_metadata, zs_cot_step=None,\n",
    "                                           sample_indices=test, augs=1, temperature=0,\n",
    "                                           max_tokens=1024)  # note, we use 1024 tokens for student inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c623f5",
   "metadata": {},
   "source": [
    "## Evaluate student completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "afc851ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_identifier = CompletionIdentifier(base_model, completion_key=\"zs_cot_final\", dataset_key=dataset_key,\n",
    "                                             train_key=train_key)\n",
    "completion_dataset = CompletionDataset.load(completion_identifier)\n",
    "train, test = load_train_test_split(dataset_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "21eac841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator(dataset_key, \"ft_cot_token\")\n",
    "evaluation = evaluator.evaluate_completion_dataset(completion_dataset, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a4181fbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8174442190669371,\n",
       " 'contains_answer': 0.8174442190669371,\n",
       " 'correct_format': 1.0,\n",
       " 'complete': 1.0}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_evaluation(evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
